---
title: 'EchoWhisper: Exploring an Acoustic-based Silent Speech Interface for Smartphone
  Users'
authors:
- Yang Gao
- Yincheng Jin
- Jiyang Li
- Seokmin Choi
- Zhanpeng Jin
date: '2020-09-01'
publishDate: '2025-07-06T09:47:45.971330Z'
publication_types:
- article-journal
publication: '*Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous
  Technologies*'
doi: 10.1145/3411830
abstract: 'With the rapid growth of artificial intelligence and mobile computing,
  intelligent speech interface has recently become one of the prevalent trends and
  has already presented huge potentials to the public. To address the privacy leakage
  issue during the speech interaction or accommodate some special demands, silent
  speech interfaces have been proposed to enable people’s communication without vocalizing
  their sound (e.g., lip reading, tongue tracking). However, most existing silent
  speech mechanisms require either background illuminations or additional wearable
  devices. In this study, we propose the EchoWhisper as a novel user-friendly, smartphone-based
  silent speech interface. The proposed technique takes advantage of the micro-Doppler
  effect of the acoustic wave resulting from mouth and tongue movements and assesses
  the acoustic features of beamformed reflected echoes captured by the dual microphones
  in the smartphone. Using human subjects who perform a daily conversation task with
  over 45 different words, our system can achieve a WER (word error rate) of 8.33%,
  which shows the effectiveness of inferring silent speech content. Moreover, EchoWhisper
  has also demonstrated its reliability and robustness to a variety of configuration
  settings and environmental factors, such as smartphone orientations and distances,
  ambient noises, body motions, and so on. CCS Concepts: • Human-centered computing
  → Human computer interaction (HCI); Mobile devices; • Computer systems organization
  → Sensors and actuators.'
links:
- name: URL
  url: https://dl.acm.org/doi/10.1145/3411830
---
