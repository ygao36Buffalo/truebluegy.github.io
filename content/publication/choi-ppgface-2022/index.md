---
title: 'PPGface: Like What You Are Watching? Earphones Can \"Feel\" Your Facial Expressions'
authors:
- Seokmin Choi
- Yang Gao
- Yincheng Jin
- Se Jun Kim
- Jiyang Li
- Wenyao Xu
- Zhanpeng Jin
date: '2022-07-01'
publishDate: '2025-07-06T09:47:45.939778Z'
publication_types:
- article-journal
publication: '*Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous
  Technologies*'
doi: 10.1145/3534597
abstract: Recognition of facial expressions has been widely explored to represent
  people's emotional states. Existing facial expression recognition systems primarily
  rely on external cameras which make it less accessible and efficient in many real-life
  scenarios to monitor an individual's facial expression in a convenient and unobtrusive
  manner. To this end, we propose PPGface, a ubiquitous, easy-to-use, user-friendly
  facial expression recognition platform that leverages earable devices with built-in
  PPG sensor. PPGface understands the facial expressions through the dynamic PPG patterns
  resulting from facial muscle movements. With the aid of the accelerometer sensor,
  PPGface can detect and recognize the user's seven universal facial expressions and
  relevant body posture unobtrusively. We conducted an user study (N=20) using multimodal
  ResNet to evaluate the performance of PPGface, and showed that PPGface can detect
  different facial expressions with 93.5 accuracy and 0.93 fl-score. In addition,
  to explore the robustness and usability of our proposed platform, we conducted several
  comprehensive experiments under real-world settings. Overall results of this work
  validate a great potential to be employed in future commodity earable devices.
links:
- name: URL
  url: https://dl.acm.org/doi/10.1145/3534597
---
